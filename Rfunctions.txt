skip, play, bye, main, info

d <- read.table('data.txt',header=T)
plot(d$Y1~d$X,ann=FALSE,type="n",xlim=c(0.1,1),ylim=c(0,1))
lines(d$Y1~d$X,lwd=2)
lines(d$Y2~d$X,lwd=2,lty=2)
title("Data",xlab="X",ylab="Y")

identical(A, b)  # return true if ..say A and b are matrices with same stuff and dim, or identical vectors
class(A) #return the data type of A 


d<-read.csv("FileName.csv")


***sequences of numbers*** 
1:15
15:1 
seq(0, 10, by=0.5)
seq(5, 10, length=30)
1:length(seq)  or seq(along = my_seq)
rep(0, times = 40)
rep(c(0, 1, 2), times = 10) 
rep(c(0, 1, 2), each = 10)
paste(1:3, c("X", "Y", "Z"), sep = "")  #1X 2Y 3Z


***vectors***
num_vect < 1  #return a vector of booleans
 paste(my_char, collapse = " ") #concatenate with space in between 
unique(v) #return a vecotr with all duplicate elements removed 


***missing value*** 
bo <- is.na(a) #if a is a vector, return a vector of booleans 
sum(bo) #return total number of TRUE, thus na's
NaN (not a number)  #inf/inf, 0/0

y <- x[!is.na(x)] #y will contain all non-na values from x 



***subsetting vectors*** 
x[1:10] #get first 10 elements, index starts at 1 
y <- x[!is.na(x)] #y will contain all non-na values from x 

y[y > 0] #gives all non-negative valeus 
x[!is.na(x) & x > 0]

x[c(3, 5, 7)]
x[-c(3, 5, 7)] #get everything EXCEPT 3rd, 5th and 7th 

vect <- c(foo = 11, bar = 2, norf = NA) #vector with stuff with names 
names(vect) #to get the names

names(vect2) <- c("foo", "bar", "norf") #to assign names to a nameless vector
vect["bar"] #get just that column 

lapply(unique_vals, function(elem) elem[2]) #elem: dummy variable, return 2nd element of each element 

data <- append(data, newnumber)  #add element to a vector 


***matrices and data frames*** 

dim(my_vector) <- c(4, 5)  #row and then column
dim(my_vector) or attributes(my_vector) 
colnames(matrix) <- cnames
nrow(matrix) # gives the first value of dim (row)
ncol(matrix) 

object.size(dataframe) #check the size 

sub <- d[d$Ozone>31&d$Temp>90, ]  #you're limiting which rows you're selecting 
#subset of rows of the data frame where Ozone values are above 31 and Temp values are above 90.




***lapply, tapply, vapply..*** 

head(data) #preview first 6 lines

cls_list  <- lapply(flags, class) #apply class function to each col of flags (data frame) 
	#return a list of types
as.character(cls_list) #simplify it to a character vector 

sapply() #like lapply but simply the result 

flag_colors  <- flags[, 11:17] #want all rows but only col 11:17 
lapply(flag_colors, sum) #loop through each col in flag_colors, apply sum function on it


***vapply,tapply ****

vapply(flags, unique, numeric(1)) 
#expects each element of the result to be a numeric vector of length 1

table(flags$animate) #to see how many flags contain an animate image 
# data$cateogry, to see how many items in the data belong to each class in the category 

tapply(flags$animate, flags$landmass, mean) 
#proportion of flags containing an animate image within each landmass class 
#tapply(a, b, c), a is our interest, b is to put them in category, c is function 


****View data**** 

nrow(matrix) # gives the first value of dim (row)
ncol(matrix) 
names(matrix) #gives column names 
object.size(dataframe) #check the size 
head(data, 10) #see first 10 
tail(data, 10) # see last 10 rows
table( ) #kind of like summary() but for smaller things, like one column
str( ) #gives number of obs, variables, preview of each one, very general and can use on most objects 



***Stimulation - random number generation***
sample(1:6, 4, replace = TRUE) #replace = TRUE means the smae number can show up again
	#by default replace is false 

sample(LETTERS) #shuffle 
sample(c(0,1), 100, p = c(0.3, 0.7), replace= TRUE) #0 has 30% chance and 1 has 70% chance 

Each probability distribution in R has an r*** function (for "random"), a d***
| function (for "density"), a p*** (for "probability"), and q*** (for "quantile").

rbinom(1, size = 100, prob = 0.7)  #generate one with success of 70% chance 
flips2  <- rbinom(n=100, size = 1, prob = 0.7) # to see 100 observatiosn 

rnorm(10, mean = 100, sd = 25 ) #generates number from normal distribution, specifying mean and SD
replicate(100, rpois(5,10) # genereate 1000 grousp of 5 randomly generated numbers 1~10 

his(data) #draw histogram 
cetral limit theorem ? 


***Dates and Time*** 
Dates -  Date class
Time - POSIXct and POSIXlt classes
ssince 1970-01-01  

d1 <- Sys.Date() to get the current date

unclass(d1) #to see what d1 is like internally 
d2  <- as.Date("1969-01-01") #to make a Date object prior to 1970 
unclass(d2)#returns -365 because that's before 1970 

t1  <- Sys.time() #get current date and time 

Sys.time() returns an object of class
| POSIXct, but we can coerce the result to POSIXlt
| with as.POSIXlt(Sys.time()


weekdays(d1) #return the day of the week from a date/time object 
quarter(t2)
months(t1) 

 t3  <- "October 17, 1986 08:24" 
strptime(t3, "%B %d, %Y %H:%M") #converts t3 into a time object 

Sys.time() - t1 #check how much the time has passsed 
difftime(Sys.time(), t1, units = 'days') #check time passed with unit specified 


to learn more, check out the lubridate package by Hadley Wickham.


***statistics*** 
range(cars$prices)
summary(data) 
cbind(patients, data) #bind by column, but coerced into characters 
data.frame(patients, data) #use this instead
sum(aVector)
mean(aVector)
median(aVector) 
sort(mpg.midsize) #sort values from smallest to largest

measurement of central tendency: mean, mode, and median 
measurements of variability: interquartile range, variance, standard deviation 

sd(aVector)  #standard deviation, variance is the square of that 

rnorm(1000) #1000 draws from a standard normal distributions 

sample(vector, 100) #draw 100 stuff from vector 


***Reading Files*** 
dataset_url <- "http://s3.amazonaws.com/practice_assignment/diet_data.zip"
download.file(dataset_url, "diet_data.zip")
unzip("diet_data.zip", exdir = "diet_data")
list.files("diet_data") #return content of the directory 

#two ways to subset 
day_25 <- andy_david[andy_david$Day == 25, ] 
dat_30 <- dat[dat[, "Day"] == 30,]


#if files are not in the working directory
files_full <- list.files("diet_data", full.names=TRUE) 

#get only complete cases
f<- read.csv(files[i])
good<-complete.cases(f)
correlation<-cor(f[good,"nitrate"], f[good, "sulfate"])


# read files

gdURL <- "http..." 
gData <- read.delim(file = gdURL)
str(gData) 